{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaitanya1081/Chaitanya_INFO5731_FALL2024/blob/main/INFO5731_Assignment_2_1_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Tuesday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (40 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from G2 or Capterra.\n",
        "\n",
        "(4) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the Densho Digital Repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jDyTKYs-yGit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "73dc690f-ff16-4ee4-c047-087ffc31c6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Fetching page 1...\n",
            "Fetching page 2...\n",
            "Fetching page 3...\n",
            "Fetching page 4...\n",
            "Fetching page 5...\n",
            "Fetching page 6...\n",
            "Fetching page 7...\n",
            "Fetching page 8...\n",
            "Fetching page 9...\n",
            "Fetching page 10...\n",
            "Fetching page 11...\n",
            "Fetching page 12...\n",
            "Fetching page 13...\n",
            "Fetching page 14...\n",
            "Fetching page 15...\n",
            "Fetching page 16...\n",
            "Fetching page 17...\n",
            "Fetching page 18...\n",
            "Fetching page 19...\n",
            "Fetching page 20...\n",
            "Fetching page 21...\n",
            "Fetching page 22...\n",
            "Fetching page 23...\n",
            "Fetching page 24...\n",
            "Fetching page 25...\n",
            "Fetching page 26...\n",
            "Fetching page 27...\n",
            "Fetching page 28...\n",
            "Fetching page 29...\n",
            "Fetching page 30...\n",
            "Fetching page 31...\n",
            "Fetching page 32...\n",
            "Fetching page 33...\n",
            "Fetching page 34...\n",
            "Fetching page 35...\n",
            "Fetching page 36...\n",
            "Fetching page 37...\n",
            "Fetching page 38...\n",
            "Fetching page 39...\n",
            "Fetching page 40...\n",
            "Fetching page 41...\n",
            "Fetching page 42...\n",
            "Fetching page 43...\n",
            "Fetching page 44...\n",
            "Fetching page 45...\n",
            "Fetching page 46...\n",
            "Fetching page 47...\n",
            "Fetching page 48...\n",
            "Fetching page 49...\n",
            "Fetching page 50...\n",
            "Saved 250 reviews to 'amazon_reviews.csv'.\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Your ScraperAPI key\n",
        "SCRAPER_API_KEY = '40b0015e08c30991680bb064ab9565f3'  # Replace with your ScraperAPI key\n",
        "\n",
        "# Function to fetch the HTML content using ScraperAPI\n",
        "def fetch_html_with_scraperapi(url):\n",
        "    api_url = f'http://api.scraperapi.com?api_key={SCRAPER_API_KEY}&url={url}&render=true'\n",
        "    response = requests.get(api_url)\n",
        "    return response.text\n",
        "\n",
        "# Function to parse and extract reviews\n",
        "def parse_amazon_reviews(soup):\n",
        "    reviews = soup.find_all('div', {'data-hook': 'review'})\n",
        "    review_list = []\n",
        "\n",
        "    for review in reviews:\n",
        "        try:\n",
        "            review_title = review.find('a', {'data-hook': 'review-title'}).text.strip()\n",
        "            review_content = review.find('span', {'data-hook': 'review-body'}).text.strip()\n",
        "            review_author = review.find('span', {'class': 'a-profile-name'}).text.strip()\n",
        "            review_rating = review.find('i', {'data-hook': 'review-star-rating'}).text.strip()\n",
        "\n",
        "            review_list.append({\n",
        "                'Title': review_title,\n",
        "                'Content': review_content,\n",
        "                'Author': review_author,\n",
        "                'Rating': review_rating\n",
        "            })\n",
        "        except:\n",
        "            continue  # Skip any reviews with missing data\n",
        "\n",
        "    return review_list\n",
        "\n",
        "# Amazon product reviews URL (example URL, replace with the actual product reviews link)\n",
        "product_url = 'https://www.amazon.com/Samsung-Galaxy-Note-10-Unlocked/dp/B07Z3XZDT5'  # Replace with the actual product reviews URL\n",
        "\n",
        "# Initialize a list to hold all reviews\n",
        "all_reviews = []\n",
        "\n",
        "# Loop through review pages (pagination)\n",
        "for page_num in range(1, 51):  # Adjust the range to collect more pages (50 pages x 10 reviews per page = 500 reviews)\n",
        "    print(f\"Fetching page {page_num}...\")\n",
        "\n",
        "    paginated_url = f\"{product_url}?pageNumber={page_num}\"\n",
        "    html_content = fetch_html_with_scraperapi(paginated_url)\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Parse the reviews from the current page\n",
        "    reviews = parse_amazon_reviews(soup)\n",
        "    all_reviews.extend(reviews)\n",
        "\n",
        "    # Sleep for a bit to avoid overloading the server\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Stop when you reach the target number of reviews\n",
        "    if len(all_reviews) >= 1000:\n",
        "        break\n",
        "\n",
        "# Save the reviews to a CSV file\n",
        "df = pd.DataFrame(all_reviews)\n",
        "df.to_csv('amazon_reviews.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"Saved {len(all_reviews)} reviews to 'amazon_reviews.csv'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (30 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk pandas\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the data from the CSV file\n",
        "df = pd.read_csv('amazon_reviews.csv')\n",
        "\n",
        "# Initialize stopwords, stemmer, and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    # 1. Remove special characters and punctuations\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # 2. Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # 3. Tokenize and remove stopwords\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # 4. Lowercase all text\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # 5. Stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # 6. Lemmatization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # Join tokens back to string\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the clean_text function to the 'Content' column and create a new 'Cleaned_Content' column\n",
        "df['Cleaned_Content'] = df['Content'].apply(clean_text)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "df.to_csv('amazon_reviews_cleaned.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"Cleaned data saved to 'amazon_reviews_cleaned.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJc4-lEmtmcN",
        "outputId": "ebeba4aa-602a-4b0c-a80d-0de5425c930b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to 'amazon_reviews_cleaned.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (30 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas nltk spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install -U spacy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiiHT3u7w2-0",
        "outputId": "c0b3220c-ce3b-400d-d406-f3de484bd0de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.3.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.3.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example clean text\n",
        "clean_text = \"\"\"\n",
        "edit august two year later phone still go strong even use phone throughout day need charg everi hour phone case kept protect still look brand new still run like new even though phone renew ive never issu requir troubleshoot repair ever replac phone im buy renewedorigin review product review first wanna discus satisfact fact renew itemth phone arriv neat littl box gener brand charg cabl adapt neither item suit fastcharg capabl phone bought item phone im gonna knock cord adapt phone look brand new scratch damag kind even much fingerprint itth phone power fine abl get setup without hitch far im concern excel job renew there way tell even renew except gener box cabl charger btw product come earbud anyth get phone gener cord gener adapt overal im happi buy renew save brand new pricea review phone first samsung phone ive never much seen galaxi note eye therefor im still learn thing say love stereo speaker great play music game sound nice punch better phone speaker ive ever heard worri wouldnt get use lack headphon jack dont actual need bought nice pair bluetooth headphon cant think reason would need headphon jackth screen realli nice amaz fingerprint scanner insid screen make unlock phone quit easi free hold phone awkwardli like phone hole punch camera screen much le distract thought would end hardli notic sinc fingerprint scanner locat insid screen cant get tradit otterbox case phone heavi duti screen protector doesnt allow fingerprint scan buy specif stickon screen protector phone case bought armadillotek case love iti like extra storag phone past alway felt like phone fill stuff quickli also previou phone prone becom slow fill app photo music phoneiv given everyth use like gig plenti space well fast chip set phone make phone lightn fasta batteri life last long time your text listen music period surf web phone last approxim hour singl charg your play game powerconsum thing believ phone might get pretti rigor hoursthi phone came preload useless app didnt come preload use app gener come android like music player amazon suchload end load samsung musicwhich alreadi love way itun appl musicim still learn use stylu pen believ ton way use pen ive tri far great especi like abl handwrit note convert text wish could say phone im still learn overal im happi purchas well worth money highli recommend read\n",
        "\"\"\"\n",
        "\n",
        "# Function for Parts of Speech tagging\n",
        "def pos_tagging(text):\n",
        "    doc = nlp(text)\n",
        "    pos_counts = Counter(token.pos_ for token in doc)\n",
        "    return pos_counts\n",
        "\n",
        "# Function for Dependency Parsing\n",
        "def dependency_parsing(text):\n",
        "    doc = nlp(text)\n",
        "    dependency_trees = []\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        dependency_trees.append([(token.text, token.dep_, token.head.text) for token in sent])\n",
        "\n",
        "    return dependency_trees\n",
        "\n",
        "# Function for Named Entity Recognition\n",
        "def named_entity_recognition(text):\n",
        "    doc = nlp(text)\n",
        "    entities = Counter((ent.text, ent.label_) for ent in doc.ents)\n",
        "    return entities\n",
        "\n",
        "# Conduct analysis\n",
        "pos_counts = pos_tagging(clean_text)\n",
        "dependency_trees = dependency_parsing(clean_text)\n",
        "entities = named_entity_recognition(clean_text)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nParts of Speech Counts:\")\n",
        "print(f\"Nouns: {pos_counts['NOUN']}\")\n",
        "print(f\"Verbs: {pos_counts['VERB']}\")\n",
        "print(f\"Adjectives: {pos_counts['ADJ']}\")\n",
        "print(f\"Adverbs: {pos_counts['ADV']}\")\n",
        "\n",
        "print(\"\\nDependency Parsing Trees:\")\n",
        "for sent_tree in dependency_trees:\n",
        "    print(sent_tree)\n",
        "\n",
        "print(\"\\nNamed Entities:\")\n",
        "for entity, count in entities.items():\n",
        "    print(f\"{entity[0]}: {entity[1]}, Count: {count}\")\n",
        "\n",
        "# Example Explanation\n",
        "print(\"\\nExample Explanation:\")\n",
        "example_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "example_doc = nlp(example_sentence)\n",
        "print(\"Example Sentence:\", example_sentence)\n",
        "print(\"Dependency Tree:\", [(token.text, token.dep_, token.head.text) for token in example_doc])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsFdXhd7xh8a",
        "outputId": "828bd0e6-11a7-4342-ea83-2a39565cd8a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parts of Speech Counts:\n",
            "Nouns: 162\n",
            "Verbs: 62\n",
            "Adjectives: 37\n",
            "Adverbs: 25\n",
            "\n",
            "Dependency Parsing Trees:\n",
            "[('\\n', 'dep', 'edit'), ('edit', 'npadvmod', 'go'), ('august', 'npadvmod', 'edit'), ('two', 'nummod', 'year'), ('year', 'npadvmod', 'later'), ('later', 'amod', 'phone'), ('phone', 'nsubj', 'go'), ('still', 'advmod', 'go'), ('go', 'ROOT', 'go'), ('strong', 'acomp', 'go'), ('even', 'advmod', 'use'), ('use', 'advcl', 'go'), ('phone', 'dobj', 'use'), ('throughout', 'prep', 'use'), ('day', 'pobj', 'throughout'), ('need', 'conj', 'go'), ('charg', 'amod', 'hour'), ('everi', 'amod', 'hour'), ('hour', 'compound', 'case'), ('phone', 'compound', 'case'), ('case', 'nsubj', 'kept'), ('kept', 'conj', 'go'), ('protect', 'xcomp', 'kept'), ('still', 'advmod', 'look'), ('look', 'xcomp', 'kept'), ('brand', 'npadvmod', 'new'), ('new', 'acomp', 'look'), ('still', 'advmod', 'run'), ('run', 'dep', 'go'), ('like', 'prep', 'run'), ('new', 'pobj', 'like'), ('even', 'advmod', 'though'), ('though', 'prep', 'go'), ('phone', 'compound', 'renew'), ('renew', 'pobj', 'though')]\n",
            "[('i', 'nsubj', 'issu'), ('ve', 'aux', 'issu'), ('never', 'neg', 'issu'), ('issu', 'ROOT', 'issu'), ('requir', 'dobj', 'issu'), ('troubleshoot', 'nmod', 'repair'), ('repair', 'ccomp', 'issu'), ('ever', 'advmod', 'repair'), ('replac', 'compound', 'phone'), ('phone', 'npadvmod', 'repair')]\n",
            "[('i', 'nsubj', 'buy'), ('m', 'aux', 'buy'), ('buy', 'ROOT', 'buy'), ('renewedorigin', 'amod', 'review'), ('review', 'compound', 'review'), ('product', 'compound', 'review'), ('review', 'nsubj', 'adapt'), ('first', 'amod', 'wanna'), ('wanna', 'compound', 'fact'), ('discus', 'compound', 'fact'), ('satisfact', 'compound', 'fact'), ('fact', 'compound', 'renew'), ('renew', 'acl', 'review'), ('itemth', 'compound', 'cabl'), ('phone', 'compound', 'gener'), ('arriv', 'compound', 'neat'), ('neat', 'compound', 'littl'), ('littl', 'compound', 'gener'), ('box', 'compound', 'gener'), ('gener', 'compound', 'cabl'), ('brand', 'compound', 'charg'), ('charg', 'compound', 'cabl'), ('cabl', 'nsubj', 'adapt'), ('adapt', 'conj', 'buy'), ('neither', 'det', 'suit'), ('item', 'compound', 'suit'), ('suit', 'nsubj', 'bought'), ('fastcharg', 'amod', 'phone'), ('capabl', 'amod', 'phone'), ('phone', 'nsubj', 'bought'), ('bought', 'ccomp', 'adapt'), ('item', 'compound', 'phone'), ('phone', 'dobj', 'bought'), ('i', 'nsubj', 'gon'), ('m', 'aux', 'gon'), ('gon', 'ccomp', 'bought'), ('na', 'aux', 'knock'), ('knock', 'xcomp', 'gon'), ('cord', 'compound', 'adapt'), ('adapt', 'ccomp', 'knock'), ('phone', 'compound', 'look'), ('look', 'nmod', 'damag'), ('brand', 'nmod', 'scratch'), ('new', 'amod', 'scratch'), ('scratch', 'compound', 'damag'), ('damag', 'compound', 'kind'), ('kind', 'dobj', 'adapt'), ('even', 'advmod', 'much'), ('much', 'amod', 'fingerprint'), ('fingerprint', 'dobj', 'knock'), ('itth', 'compound', 'fine'), ('phone', 'compound', 'power'), ('power', 'compound', 'fine'), ('fine', 'advcl', 'buy')]\n",
            "[('abl', 'nsubj', 'get'), ('get', 'ROOT', 'get'), ('setup', 'dobj', 'get'), ('without', 'prep', 'get'), ('hitch', 'pobj', 'without'), ('far', 'advmod', 'm'), ('i', 'nsubj', 'm'), ('m', 'advcl', 'get'), ('concern', 'compound', 'renew'), ('excel', 'compound', 'renew'), ('job', 'compound', 'renew'), ('renew', 'attr', 'm'), ('there', 'advmod', 'renew'), ('way', 'npadvmod', 'get'), ('tell', 'dep', 'get'), ('even', 'advmod', 'renew'), ('renew', 'xcomp', 'tell'), ('except', 'prep', 'renew'), ('gener', 'compound', 'charger'), ('box', 'compound', 'cabl'), ('cabl', 'compound', 'charger'), ('charger', 'nmod', 'product'), ('btw', 'compound', 'product'), ('product', 'pobj', 'except'), ('come', 'xcomp', 'tell'), ('earbud', 'compound', 'anyth'), ('anyth', 'npadvmod', 'come')]\n",
            "[('get', 'ROOT', 'get'), ('phone', 'compound', 'gener'), ('gener', 'compound', 'gener'), ('cord', 'compound', 'gener'), ('gener', 'nsubj', 'adapt'), ('adapt', 'ccomp', 'get'), ('overal', 'dobj', 'adapt'), ('i', 'nsubj', 'm'), ('m', 'ccomp', 'adapt'), ('happi', 'nsubj', 'buy'), ('buy', 'ccomp', 'adapt'), ('renew', 'dobj', 'buy'), ('save', 'dep', 'get'), ('brand', 'nmod', 'phone'), ('new', 'amod', 'phone'), ('pricea', 'compound', 'review'), ('review', 'compound', 'phone'), ('phone', 'dobj', 'save'), ('first', 'advmod', 'phone'), ('samsung', 'compound', 'phone'), ('phone', 'dobj', 'save'), ('i', 'nsubj', 'seen'), ('ve', 'aux', 'seen'), ('never', 'neg', 'seen'), ('much', 'advmod', 'seen'), ('seen', 'relcl', 'phone'), ('galaxi', 'compound', 'note'), ('note', 'compound', 'eye'), ('eye', 'dobj', 'seen'), ('therefor', 'dep', 'get'), ('i', 'nsubj', 'learn'), ('m', 'aux', 'learn'), ('still', 'advmod', 'learn'), ('learn', 'ccomp', 'get'), ('thing', 'nsubj', 'say'), ('say', 'ccomp', 'learn'), ('love', 'compound', 'stereo'), ('stereo', 'compound', 'speaker'), ('speaker', 'nmod', 'sound'), ('great', 'amod', 'sound'), ('play', 'amod', 'sound'), ('music', 'compound', 'game'), ('game', 'compound', 'sound'), ('sound', 'nsubj', 'punch'), ('nice', 'amod', 'punch'), ('punch', 'ccomp', 'say'), ('better', 'amod', 'speaker'), ('phone', 'compound', 'speaker'), ('speaker', 'dobj', 'punch'), ('i', 'nsubj', 'heard'), ('ve', 'aux', 'heard'), ('ever', 'advmod', 'heard'), ('heard', 'relcl', 'speaker'), ('worri', 'dobj', 'heard'), ('would', 'aux', 'get'), ('nt', 'neg', 'get'), ('get', 'ccomp', 'say'), ('use', 'dobj', 'get'), ('lack', 'dobj', 'use'), ('headphon', 'compound', 'jack'), ('jack', 'dobj', 'get')]\n",
            "[('do', 'aux', 'need'), ('nt', 'neg', 'need'), ('actual', 'amod', 'need'), ('need', 'ROOT', 'need'), ('bought', 'acl', 'need'), ('nice', 'compound', 'pair'), ('pair', 'dobj', 'bought')]\n",
            "[('bluetooth', 'det', 'headphon'), ('headphon', 'nsubj', 'think'), ('ca', 'aux', 'think'), ('nt', 'neg', 'think'), ('think', 'ROOT', 'think'), ('reason', 'nsubj', 'need'), ('would', 'aux', 'need'), ('need', 'ccomp', 'think'), ('headphon', 'compound', 'screen'), ('jackth', 'compound', 'screen'), ('screen', 'compound', 'realli'), ('realli', 'compound', 'nice'), ('nice', 'amod', 'fingerprint'), ('amaz', 'advmod', 'fingerprint'), ('fingerprint', 'compound', 'screen'), ('scanner', 'amod', 'screen'), ('insid', 'amod', 'screen'), ('screen', 'nsubj', 'make'), ('make', 'ccomp', 'need'), ('unlock', 'amod', 'phone'), ('phone', 'nsubj', 'quit'), ('quit', 'ccomp', 'make'), ('easi', 'dobj', 'quit'), ('free', 'amod', 'hold'), ('hold', 'compound', 'awkwardli'), ('phone', 'compound', 'awkwardli'), ('awkwardli', 'dobj', 'easi'), ('like', 'prep', 'easi'), ('phone', 'compound', 'hole'), ('hole', 'pobj', 'like'), ('punch', 'ccomp', 'make'), ('camera', 'compound', 'screen'), ('screen', 'dobj', 'punch'), ('much', 'amod', 'distract'), ('le', 'compound', 'distract'), ('distract', 'compound', 'thought'), ('thought', 'nsubj', 'end'), ('would', 'aux', 'end'), ('end', 'conj', 'think'), ('hardli', 'compound', 'scanner'), ('notic', 'compound', 'scanner'), ('sinc', 'compound', 'scanner'), ('fingerprint', 'compound', 'scanner'), ('scanner', 'compound', 'screen'), ('locat', 'nmod', 'screen'), ('insid', 'amod', 'screen'), ('screen', 'nsubj', 'get'), ('ca', 'aux', 'get'), ('nt', 'neg', 'get'), ('get', 'ccomp', 'end'), ('tradit', 'compound', 'case'), ('otterbox', 'compound', 'case'), ('case', 'compound', 'protector'), ('phone', 'compound', 'protector'), ('heavi', 'compound', 'duti'), ('duti', 'compound', 'screen'), ('screen', 'compound', 'protector'), ('protector', 'nsubj', 'allow'), ('does', 'aux', 'allow'), ('nt', 'neg', 'allow'), ('allow', 'ccomp', 'get'), ('fingerprint', 'dobj', 'allow'), ('scan', 'aux', 'buy'), ('buy', 'ccomp', 'think'), ('specif', 'amod', 'case'), ('stickon', 'amod', 'case'), ('screen', 'compound', 'case'), ('protector', 'compound', 'phone'), ('phone', 'compound', 'case'), ('case', 'dobj', 'buy'), ('bought', 'ccomp', 'think'), ('armadillotek', 'compound', 'case'), ('case', 'compound', 'love'), ('love', 'dobj', 'bought'), ('iti', 'advmod', 'love'), ('like', 'prep', 'love'), ('extra', 'amod', 'past'), ('storag', 'compound', 'phone'), ('phone', 'compound', 'past'), ('past', 'pobj', 'like'), ('alway', 'advmod', 'felt'), ('felt', 'ccomp', 'think'), ('like', 'mark', 'previou'), ('phone', 'compound', 'fill'), ('fill', 'compound', 'stuff'), ('stuff', 'compound', 'quickli'), ('quickli', 'nsubj', 'previou'), ('also', 'advmod', 'previou'), ('previou', 'advcl', 'felt'), ('phone', 'compound', 'phoneiv'), ('prone', 'amod', 'phoneiv'), ('becom', 'compound', 'app'), ('slow', 'compound', 'app'), ('fill', 'compound', 'app'), ('app', 'compound', 'phoneiv'), ('photo', 'compound', 'phoneiv'), ('music', 'compound', 'phoneiv'), ('phoneiv', 'dobj', 'previou'), ('given', 'prep', 'previou'), ('everyth', 'compound', 'use'), ('use', 'dobj', 'given'), ('like', 'prep', 'use'), ('gig', 'pobj', 'like'), ('plenti', 'conj', 'think'), ('space', 'dobj', 'plenti'), ('well', 'advmod', 'fast'), ('fast', 'amod', 'chip'), ('chip', 'nsubj', 'set'), ('set', 'ccomp', 'think'), ('phone', 'dobj', 'set'), ('make', 'ccomp', 'think'), ('phone', 'compound', 'batteri'), ('lightn', 'compound', 'batteri'), ('fasta', 'compound', 'batteri'), ('batteri', 'compound', 'life'), ('life', 'dobj', 'make'), ('last', 'amod', 'time'), ('long', 'amod', 'time'), ('time', 'npadvmod', 'listen'), ('your', 'poss', 'text'), ('text', 'nsubj', 'listen'), ('listen', 'advcl', 'charg'), ('music', 'compound', 'period'), ('period', 'compound', 'surf'), ('surf', 'compound', 'phone'), ('web', 'compound', 'phone'), ('phone', 'dobj', 'listen'), ('last', 'amod', 'approxim'), ('approxim', 'compound', 'singl'), ('hour', 'compound', 'singl'), ('singl', 'nsubj', 'charg'), ('charg', 'ccomp', 'think'), ('your', 'poss', 'thing'), ('play', 'compound', 'powerconsum'), ('game', 'compound', 'powerconsum'), ('powerconsum', 'compound', 'thing'), ('thing', 'dobj', 'charg'), ('believ', 'compound', 'phone'), ('phone', 'nsubj', 'get'), ('might', 'aux', 'get'), ('get', 'ccomp', 'think'), ('pretti', 'compound', 'rigor'), ('rigor', 'nsubj', 'came'), ('hoursthi', 'amod', 'phone'), ('phone', 'appos', 'rigor'), ('came', 'ccomp', 'get'), ('preload', 'npadvmod', 'useless'), ('useless', 'amod', 'app'), ('app', 'nsubj', 'come'), ('did', 'aux', 'come'), ('nt', 'neg', 'come'), ('come', 'ccomp', 'think'), ('preload', 'compound', 'use'), ('use', 'compound', 'gener'), ('app', 'compound', 'gener'), ('gener', 'nsubj', 'come'), ('come', 'ccomp', 'think'), ('android', 'acomp', 'come'), ('like', 'prep', 'come'), ('music', 'compound', 'player'), ('player', 'compound', 'suchload'), ('amazon', 'compound', 'suchload'), ('suchload', 'compound', 'load'), ('end', 'compound', 'load'), ('load', 'compound', 'way'), ('samsung', 'compound', 'musicwhich'), ('musicwhich', 'compound', 'way'), ('alreadi', 'compound', 'love'), ('love', 'compound', 'way'), ('way', 'compound', 'musicim'), ('itun', 'compound', 'musicim'), ('appl', 'compound', 'musicim'), ('musicim', 'nsubj', 'learn'), ('still', 'advmod', 'learn'), ('learn', 'pcomp', 'like'), ('use', 'xcomp', 'learn'), ('stylu', 'poss', 'use'), ('pen', 'compound', 'way'), ('believ', 'compound', 'ton'), ('ton', 'compound', 'way'), ('way', 'compound', 'use'), ('use', 'ccomp', 'think'), ('pen', 'dobj', 'use')]\n",
            "[('i', 'nsubj', 'tri'), ('ve', 'aux', 'tri'), ('tri', 'ccomp', 'say'), ('far', 'advmod', 'great'), ('great', 'amod', 'especi'), ('especi', 'dobj', 'tri'), ('like', 'prep', 'especi'), ('abl', 'compound', 'note'), ('handwrit', 'compound', 'note'), ('note', 'nmod', 'wish'), ('convert', 'amod', 'wish'), ('text', 'compound', 'wish'), ('wish', 'pobj', 'like'), ('could', 'aux', 'say'), ('say', 'ROOT', 'say'), ('phone', 'punct', 'say')]\n",
            "[('i', 'nsubj', 'learn'), ('m', 'aux', 'learn'), ('still', 'advmod', 'learn'), ('learn', 'ROOT', 'learn'), ('overal', 'dobj', 'learn'), ('i', 'nsubj', 'm'), ('m', 'ccomp', 'learn'), ('happi', 'attr', 'm'), ('purchas', 'ccomp', 'learn'), ('well', 'advmod', 'worth'), ('worth', 'amod', 'highli'), ('money', 'compound', 'highli'), ('highli', 'nsubj', 'recommend'), ('recommend', 'ccomp', 'learn'), ('read', 'dobj', 'recommend'), ('\\n', 'dep', 'read')]\n",
            "\n",
            "Named Entities:\n",
            "august two year later: DATE, Count: 1\n",
            "day: DATE, Count: 1\n",
            "everi hour: PERSON, Count: 1\n",
            "issu requir troubleshoot: PERSON, Count: 1\n",
            "first: ORDINAL, Count: 2\n",
            "gener: ORG, Count: 2\n",
            "jack: PERSON, Count: 1\n",
            "scan: NORP, Count: 1\n",
            "lightn fasta: PERSON, Count: 1\n",
            "hour: TIME, Count: 1\n",
            "rigor hoursthi: PERSON, Count: 1\n",
            "samsung: ORG, Count: 1\n",
            "believ ton: PERSON, Count: 1\n",
            "\n",
            "Example Explanation:\n",
            "Example Sentence: The quick brown fox jumps over the lazy dog.\n",
            "Dependency Tree: [('The', 'det', 'fox'), ('quick', 'amod', 'fox'), ('brown', 'amod', 'fox'), ('fox', 'nsubj', 'jumps'), ('jumps', 'ROOT', 'jumps'), ('over', 'prep', 'jumps'), ('the', 'det', 'dog'), ('lazy', 'amod', 'dog'), ('dog', 'pobj', 'over'), ('.', 'punct', 'jumps')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Comment**\n",
        "Make sure to submit the cleaned data CSV in the comment section - 10 points"
      ],
      "metadata": {
        "id": "CXNn1lEVbMsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ],
      "metadata": {
        "id": "q8BFCvWp32cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your response below"
      ],
      "metadata": {
        "id": "_e557s2w4BpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}